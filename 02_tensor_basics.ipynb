{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNMR4EwYmCzNqNenLuN/ctu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Roghiehghahremani/Deep-Learning-With-PyTorch---Full-Course_Patrick-Loeber/blob/main/02_tensor_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIGOmplBp2nK",
        "outputId": "fcefa477-7d81-4ba8-cdd2-dd659d2768bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.])\n",
            "tensor([-2.2305e-37,  4.4736e-41, -2.2305e-37])\n",
            "tensor([[ 1.6905e-34,  0.0000e+00, -2.2305e-37],\n",
            "        [ 4.4736e-41,  8.9683e-44,  0.0000e+00]])\n",
            "tensor([[[1.8899e-34, 0.0000e+00, 0.0000e+00],\n",
            "         [2.3510e-38, 1.3500e-37, 0.0000e+00]],\n",
            "\n",
            "        [[1.0842e-19, 0.0000e+00, 0.0000e+00],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00]]])\n",
            "tensor([[0.2854, 0.3616, 0.6162],\n",
            "        [0.4577, 0.3565, 0.7534],\n",
            "        [0.1146, 0.7010, 0.8851],\n",
            "        [0.6500, 0.3507, 0.6226],\n",
            "        [0.2699, 0.3456, 0.9516]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Everything in pytorch is based on Tensor operations.\n",
        "# A tensor can have different dimensions\n",
        "# so it can be 1d, 2d, or even 3d and higher\n",
        "\n",
        "# scalar, vector, matrix, tensor\n",
        "\n",
        "# torch.empty(size): uninitiallized\n",
        "x = torch.empty(1) # scalar\n",
        "print(x)\n",
        "\n",
        "x = torch.empty(3) # vector, 1D\n",
        "print(x)\n",
        "\n",
        "x = torch.empty(2,3) # matrix, 2D\n",
        "print(x)\n",
        "\n",
        "x = torch.empty(2,2,3) # tensor, 3 dimensions\n",
        "#x = torch.empty(2,2,2,3) # tensor, 4 dimensions\n",
        "print(x)\n",
        "\n",
        "# torch.rand(size): random numbers [0, 1]\n",
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.zeros(size), fill with 0\n",
        "# torch.ones(size), fill with 1\n",
        "x = torch.zeros(5, 3)\n",
        "print(x)\n",
        "\n",
        "# check size\n",
        "print(x.size())\n",
        "\n",
        "# check data type\n",
        "print(x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drUuP61jqVz-",
        "outputId": "45a4ded2-d2b9-4072-9231-efc8e5d2a3b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "torch.Size([5, 3])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# specify types, float32 default\n",
        "x = torch.zeros(5, 3, dtype=torch.float16)\n",
        "print(x)\n",
        "\n",
        "# check type\n",
        "print(x.dtype)\n",
        "\n",
        "# construct from data\n",
        "x = torch.tensor([5.5, 3])\n",
        "print(x.size())\n",
        "print(x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irmhdoKZq9hO",
        "outputId": "61817926-a25f-45ae-9084-388d7cbe4274"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], dtype=torch.float16)\n",
            "torch.float16\n",
            "torch.Size([2])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# requires_grad argument\n",
        "# This will tell pytorch that it will need to calculate the gradients for this tensor\n",
        "# later in your optimization steps\n",
        "# i.e. this is a variable in your model that you want to optimize\n",
        "x = torch.tensor([5.5, 3], requires_grad=True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e05SKDuErGsy",
        "outputId": "ffccaf19-0737-41e4-c2a5-0ed8f34b26ca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.5000, 3.0000], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Operations\n",
        "y = torch.rand(2, 2)\n",
        "x = torch.rand(2, 2)\n",
        "\n",
        "# elementwise addition\n",
        "z = x + y\n",
        "# torch.add(x,y)\n",
        "\n",
        "# in place addition, everythin with a trailing underscore is an inplace operation\n",
        "# i.e. it will modify the variable\n",
        "# y.add_(x)\n",
        "\n",
        "# substraction\n",
        "z = x - y\n",
        "z = torch.sub(x, y)\n",
        "\n",
        "# multiplication\n",
        "z = x * y\n",
        "z = torch.mul(x,y)\n",
        "\n",
        "# division\n",
        "z = x / y\n",
        "z = torch.div(x,y)\n",
        "\n"
      ],
      "metadata": {
        "id": "gRN5MMMUrR_l"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing\n",
        "x = torch.rand(5,3)\n",
        "print(x)\n",
        "print(x[:, 0]) # all rows, column 0\n",
        "print(x[1, :]) # row 1, all columns\n",
        "print(x[1,1]) # element at 1, 1\n",
        "\n",
        "# Get the actual value if only 1 element in your tensor\n",
        "print(f'{x[1,1].item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWpjcbhbrW-J",
        "outputId": "ccc967b4-64b4-4093-ab64-2fdbd6188185"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7600, 0.4023, 0.9053],\n",
            "        [0.0694, 0.3185, 0.7521],\n",
            "        [0.0111, 0.7881, 0.7610],\n",
            "        [0.4809, 0.7753, 0.3437],\n",
            "        [0.4338, 0.1458, 0.0801]])\n",
            "tensor([0.7600, 0.0694, 0.0111, 0.4809, 0.4338])\n",
            "tensor([0.0694, 0.3185, 0.7521])\n",
            "tensor(0.3185)\n",
            "0.318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape with torch.view()\n",
        "x = torch.randn(4, 4)\n",
        "print(x)\n",
        "y = x.view(16)\n",
        "print(y)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "print(z)\n",
        "# if -1 it pytorch will automatically determine the necessary size\n",
        "print(x.size(), y.size(), z.size())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCxWjhX-rcqo",
        "outputId": "1fccb364-98f9-486a-ca25-1057a2a0d764"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.3715, -0.9183, -1.4066, -0.7870],\n",
            "        [-0.0691, -1.0372, -0.4761,  0.9875],\n",
            "        [-0.5361, -0.1050, -1.4711,  0.6948],\n",
            "        [ 1.0669,  0.5513,  0.3385, -0.5003]])\n",
            "tensor([ 2.3715, -0.9183, -1.4066, -0.7870, -0.0691, -1.0372, -0.4761,  0.9875,\n",
            "        -0.5361, -0.1050, -1.4711,  0.6948,  1.0669,  0.5513,  0.3385, -0.5003])\n",
            "tensor([[ 2.3715, -0.9183, -1.4066, -0.7870, -0.0691, -1.0372, -0.4761,  0.9875],\n",
            "        [-0.5361, -0.1050, -1.4711,  0.6948,  1.0669,  0.5513,  0.3385, -0.5003]])\n",
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Numpy\n",
        "# Converting a Torch Tensor to a NumPy array and vice versa is very easy\n",
        "a = torch.ones(5)\n",
        "print(a)\n",
        "print(a.dtype)\n",
        "# torch to numpy with .numpy()\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(type(b))\n",
        "print()\n",
        "# Carful: If the Tensor is on the CPU (not the GPU),\n",
        "# both objects will share the same memory location, so changing one\n",
        "# will also change the other\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmxTCylirfi2",
        "outputId": "215a1a35-39c7-4400-9696-64efa9974e5a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "torch.float32\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n",
            "\n",
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy to torch with .from_numpy(x)\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "print(a)\n",
        "print(b)\n",
        "print()\n",
        "# again be careful when modifying\n",
        "a += 1\n",
        "print(a)\n",
        "print(b)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bKZam4CrnsY",
        "outputId": "45ca4324-77e0-4eae-8051-4b67b924c659"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "\n",
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# by default all tensors are created on the CPU,\n",
        "# but you can also move them to the GPU (only if it's available )\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    print(device)\n",
        "    print(x)\n",
        "    print()\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    print(y)\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    print(x)\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    # z = z.numpy() # not possible because numpy cannot handle GPU tenors\n",
        "    # move to CPU again\n",
        "    z.to(\"cpu\")       # ``.to`` can also change dtype together!\n",
        "    print(z)\n",
        "    # z = z.numpy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr3qU1vEruIh",
        "outputId": "af38c28e-ebb7-40c6-85b5-143237e3e4a8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "tensor([[ 2.3715, -0.9183, -1.4066, -0.7870],\n",
            "        [-0.0691, -1.0372, -0.4761,  0.9875],\n",
            "        [-0.5361, -0.1050, -1.4711,  0.6948],\n",
            "        [ 1.0669,  0.5513,  0.3385, -0.5003]], device='cuda:0')\n",
            "\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], device='cuda:0')\n",
            "tensor([[ 2.3715, -0.9183, -1.4066, -0.7870],\n",
            "        [-0.0691, -1.0372, -0.4761,  0.9875],\n",
            "        [-0.5361, -0.1050, -1.4711,  0.6948],\n",
            "        [ 1.0669,  0.5513,  0.3385, -0.5003]], device='cuda:0')\n",
            "tensor([[ 3.3715,  0.0817, -0.4066,  0.2130],\n",
            "        [ 0.9309, -0.0372,  0.5239,  1.9875],\n",
            "        [ 0.4639,  0.8950, -0.4711,  1.6948],\n",
            "        [ 2.0669,  1.5513,  1.3385,  0.4997]], device='cuda:0')\n",
            "tensor([[ 3.3715,  0.0817, -0.4066,  0.2130],\n",
            "        [ 0.9309, -0.0372,  0.5239,  1.9875],\n",
            "        [ 0.4639,  0.8950, -0.4711,  1.6948],\n",
            "        [ 2.0669,  1.5513,  1.3385,  0.4997]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I-5aK8v_ty1v"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}